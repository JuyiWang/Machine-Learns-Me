{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning HW.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './ml2020spring-hw4'\n",
    "data_path = ['training_label.txt', 'training_nolabel.txt', 'testing_data.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path_list):\n",
    "    data_length = 1\n",
    "    data = []\n",
    "    for path in path_list:\n",
    "        with open(path, 'r',encoding = 'utf-8',newline = '\\n',errors = 'ignore') as f:\n",
    "            for line in f:\n",
    "                if '_label' in path:\n",
    "                    text = line.split(' +++$+++ ')[1]\n",
    "                elif 'test' in path:\n",
    "                    text = line.split(',')[1]\n",
    "                else:\n",
    "                    text = line\n",
    "                data.append(text)\n",
    "                data_length += 1\n",
    "    return data,data_length      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1578616"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "path_list = [os.path.join(file_path,item) for item in data_path]\n",
    "data,data_length = read_file(path_list)\n",
    "data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(data):\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    idx = 1\n",
    "    for item in data:\n",
    "        for word in item.replace('\\n','').split():\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = idx\n",
    "                idx2word[idx] = word\n",
    "                idx += 1\n",
    "    return word2idx,idx2word,idx\n",
    "\n",
    "def word_to_vector(path):\n",
    "    word2vec = {}\n",
    "    with open(path, 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            word2vec[tokens[0]] = np.asarray(tokens[1:], dtype = 'float32')\n",
    "    return word2vec\n",
    "\n",
    "def seq_to_tokens(text, word2idx, max_len):\n",
    "    unknown = idx\n",
    "    text = text.replace('\\n','').split()\n",
    "    sequence = [word2idx[word] if word in word2idx else unknown for word in text]\n",
    "    sequence = sequence[:max_len]\n",
    "    x = (np.ones(max_len) * 0).astype('int64')\n",
    "    x[:len(sequence)] = sequence\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word,idx = word_to_index(data)\n",
    "assert len(word2idx)+1 == idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "400000"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "word2vec = word_to_vector('glove.6B.100d.txt')\n",
    "len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_embedding_matrix(path,word2idx,dim):\n",
    "    word2vec = word_to_vector(path)\n",
    "    embedding_matrix = np.empty((len(word2idx)+2, dim))\n",
    "    for word in word2idx:\n",
    "        if word in word2vec:\n",
    "            vec = word2vec.get(word)\n",
    "            if vec is not None:\n",
    "                embedding_matrix[word2idx.get(word)] = vec\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = building_embedding_matrix('glove.6B.100d.txt',word2idx,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((255800, 100), 255799)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "embedding_matrix.shape,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet():\n",
    "\n",
    "    def __init__(self, path, word2idx, max_len = 128, data_type = 'train'):\n",
    "        all_data = []\n",
    "        with open(path, 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
    "            for lines in f:\n",
    "                if data_type == 'train':\n",
    "                    tokens = lines.replace('\\n','').split(' +++$+++ ')\n",
    "                    label = int(tokens[0])\n",
    "                else:\n",
    "                    tokens = lines.replace('\\n','').split(',')\n",
    "                    label = 0\n",
    "                seq = seq_to_tokens(tokens[1], word2idx, max_len)\n",
    "                data = {\n",
    "                    'data':seq,\n",
    "                    'label':label,\n",
    "                }\n",
    "                all_data.append(data)\n",
    "        self.data = all_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = TextDataSet(path_list[0], word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'torch.utils.data.dataloader.DataLoader'>\n64\n"
    }
   ],
   "source": [
    "train_loader = DataLoader(text, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.utils.data.dataloader.DataLoader"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,embed_dim,hidden_size,out_dim,embed_matrix):\n",
    "        super(RNN,self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype = torch.float))\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_size, batch_first = True)\n",
    "        self.func = nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size*2,out_dim),\n",
    "            nn.Dropout() \n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        tokens = self.embedding(x)\n",
    "        out,(h_t,c_t) = self.rnn(tokens)\n",
    "        out = self.func(h_t)\n",
    "        return out.reshape((64,2))\n",
    "\n",
    "    def squeeze_embedding(self,x,x_len):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([64, 2])"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}