## 吴恩达-机器学习教程笔记

### [第一周 Week_1](Notes_1.md)

**一、引言**

1.1 机器学习

1.2 监督学习

1.3 无监督学习

**二、单变量线性回归(Univariate Linear Regession)**

2.1 模型表示

2.2 代价函数

2.3 梯度下降

**三、多变量线性回归(Linear Regression)**

3.1 多维特征

3.2 多变量梯度下降

3.3 梯度下降实践-特征缩放

3.4 梯度下降实践-学习率

3.5 特征和多项式回归

3.6 正规方程

**四、逻辑回归(Logistic Regression)**

4.1 分类问题

4.2 假说表示、判定边界

4.3 代价函数和梯度下降

4.4 高级优化

**五、正则化**

5.1 欠拟合与过拟合

5.2 代价函数

5.3 正则化线性回归

5.4 正则化的逻辑回归模型

### [第二周 Week_2](Notes_2.md)

**六、神经网络:表述(Neural Networks:Representation)**

6.1 非线性假设

6.2 模型表示

6.3 样本和直观理解

6.4 多类分类

**七、神经网络:学习(Neural Networks:Learning)**

7.1 代价函数

7.2 反向传播算法

7.3 展开参数

7.4 梯度检验

7.5 随机初始化

7.6 综合

**八、应用机器学习的建议(Advice for Applying Machine Learning)**

8.1 决定下一步做什么

8.2 评估一个假设

8.3 模型选择和交叉验证集

8.4 诊断偏差和方差

8.5 正则化和偏差/方差

8.6 学习曲线

8.7 决定下一步做什么

**九、机器学习系统的设计(Machine Learning System Design)**

9.1 首先要做什么

9.2 误差分析

9.3 类偏斜的误差度量

9.4 查准率和查全率之间的权衡

9.5 机器学习的数据

### [第三周 Week_3](Notes_3.md)

**十、支持向量机(Support Vector Machines)**

10.1 优化目标

10.2 大边界的直观理解

10.3 大边界分类背后的数学（选修）

10.4 核函数

10.5 使用支持向量机

**十一、聚类(Clustering)**

11.1 无监督学习：简介

11.2 K-均值算法

11.3 优化目标

11.4 随机初始化

11.5 选择聚类数

**十二、降维(Dimensionality Reduction)**

12.1 动机一：数据压缩

12.2 动机二：数据可视化

12.3 主成分分析问题

12.4 主成分分析算法

12.5 选择主成分的数量

12.6 重建的压缩表示

12.7 主成分分析法的应用建议

**十三、异常检测(Anomaly Detection)**

13.1 问题的动机

13.2 高斯分布

13.3 算法

13.4 开发和评价一个异常检测系统

13.5 异常检测与监督学习对比

13.6 选择特征

13.7 多元高斯分布（选修）

13.8 使用多元高斯分布进行异常检测（选修）

### [第四周 Week_4](Notes_4.md)

**十四、推荐系统(Recommender Systems)**

14.1 问题形式化

14.2 基于内容的推荐系统

14.3 协同过滤

14.4 向量化：低秩矩阵分解

14.5 推行工作上的细节：均值归一化

**十五、大规模机器学习(Large Scale Machine Learning)**

15.1 大型数据集的学习

15.2 随机梯度下降法

15.3 小批量梯度下降

15.4 随机梯度下降收敛

15.5 在线学习

15.6 映射化简和数据并行

**十六、应用实例：图片文字识别(Application Example: Photo OCR)**

16.1 问题描述和流程图

16.2 滑动窗口

16.3 获取大量数据和人工数据

16.4 上限分析：哪部分管道的接下去做

**十七、总结(Conclusion)**
